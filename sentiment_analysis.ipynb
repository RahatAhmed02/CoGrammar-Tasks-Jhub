{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78acc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28332, 24)\n",
      "\n",
      "Review: 1, bulk expensive way products like\n",
      "Sentiment: Sentiment(polarity=-0.5, subjectivity=0.7)\n",
      "Mood: Negative\n",
      "\n",
      "Review: 25, battery battery good price\n",
      "Sentiment: Sentiment(polarity=0.7, subjectivity=0.6000000000000001)\n",
      "Mood: Positive\n",
      "\n",
      "Review: 54, arrived earlier expected amazon batteries affordable long life\n",
      "Sentiment: Sentiment(polarity=-0.05000000000000001, subjectivity=0.43333333333333335)\n",
      "Mood: Neutral\n",
      "\n",
      "Review: 76, purchased work far\n",
      "Sentiment: Sentiment(polarity=0.1, subjectivity=1.0)\n",
      "Mood: Neutral\n",
      "\n",
      "Review: 100, teacher need tons batteries refused spend excessive amounts figured best option long lasting worth money cute matters lol wo find deal like stores!i highly recommend\n",
      "Sentiment: Sentiment(polarity=0.3075, subjectivity=0.505)\n",
      "Mood: Positive\n",
      "\n",
      "Review: 299, house uses batteries fast like purchasing bulk purchase little cheaper way little nervous purchase amazonbasics brand wanted sure purchased quality battery normally purchase duracell happy quality good brands purchase fraction cost purchasing future\n",
      "Sentiment: Sentiment(polarity=0.24687499999999998, subjectivity=0.6079861111111111)\n",
      "Mood: Positive\n",
      "\n",
      "Review: 804, worked tools controllers cheap nt forget recycle\n",
      "Sentiment: Sentiment(polarity=0.4, subjectivity=0.7)\n",
      "Mood: Positive\n",
      "\n",
      "Review: 3202, beat price point\n",
      "Sentiment: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Mood: Neutral\n",
      "\n",
      "Review: 6043, batteries work cost fraction price regular ones happy\n",
      "Sentiment: Sentiment(polarity=0.4, subjectivity=0.5384615384615384)\n",
      "Mood: Positive\n",
      "\n",
      "Review: 13598, loved good screen quality clarity course amazon alot regular google play store stuff androids nt available version stuff good kids loved loved highly recommend buying hooked google play d samsung tablet\n",
      "Sentiment: Sentiment(polarity=0.5075000000000001, subjectivity=0.5771153846153846)\n",
      "Mood: Positive\n",
      "\n",
      "First Review: I use them for my Xbox controllers and they last pretty long. Great for a cheap price.\n",
      "Second Review: I bought this as a Christmas present for my sister and she LOVES it. It's easy to use, lightweight and doesn't seem to have a lot of bugs or glitches. It's a good source of entertainment for when she's at work but has down-time. She passes the time reading ebooks, browsing the web and playing games.\n",
      "Similarity: 0.8835282245905531\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "# Initialise spaCy with 'en_core_web_sm' model and add SpacyTextBlob component to pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "# Initialise a separate spaCy model 'en_core_web_md' for computing similarity as it includes word vectors\n",
    "nlpx = spacy.load('en_core_web_md')\n",
    "\n",
    "# Load reviews from a CSV file and remove rows where the 'reviews.text' column is empty\n",
    "df = pd.read_csv('amazon_product_reviews.csv', sep=',')\n",
    "reviews_data = df['reviews.text'].dropna()\n",
    "\n",
    "# Understand the size of the data frame\n",
    "print(df.shape)\n",
    "\n",
    "# Function to clean reviews\n",
    "def clean_reviews(product_reviews):\n",
    "    # Dictionary to store cleaned reviews\n",
    "    cleaned_reviews = {}\n",
    "    \n",
    "    # Loop over the reviews data using the index\n",
    "    for index in product_reviews.index:\n",
    "        review = product_reviews[index]\n",
    "        # Process the text of the review with spaCy\n",
    "        doc = nlp(review)\n",
    "        # List of tokens stripped, lower case, no stop words, no punctuation, no whitespace\n",
    "        cleaned_review = [\n",
    "            token.text.strip().lower() for token in doc \n",
    "            if not token.is_stop and not token.is_punct and not token.text.isspace()\n",
    "        ]\n",
    "        \n",
    "        # Join the tokens back into a string and store in a dictionary with the review's index as the key\n",
    "        cleaned_reviews[index] = \" \".join(cleaned_review)\n",
    "        \n",
    "    return cleaned_reviews\n",
    "\n",
    "# Function to perform sentiment analysis on the reviews\n",
    "def sentiment_analysis(reviews):\n",
    "    for key, value in reviews.items():\n",
    "        # Process the text with spaCy\n",
    "        doc = nlp(value)\n",
    "        \n",
    "        # Calculate polarity and assign mood based on the polarity score\n",
    "        polarity = doc._.blob.polarity\n",
    "        if -0.15 <= polarity <= 0.15:\n",
    "            Mood = \"Neutral\"\n",
    "        elif -1 <= polarity < -0.15:\n",
    "            Mood = \"Negative\"\n",
    "        elif 0.15 < polarity <= 1:\n",
    "            Mood = \"Positive\"\n",
    "            \n",
    "        # Print the review, its sentiment, and mood\n",
    "        print(f\"\\nReview: {key}, {value}\")\n",
    "        print(f\"Sentiment: {doc._.blob.sentiment}\")\n",
    "        print(f\"Mood: {Mood}\")\n",
    "\n",
    "# Sample of reviews to analyse to reduce computational load\n",
    "reviews_data_sample = reviews_data.iloc[[1, 25, 54, 76, 100, 299, 804, 3202, 6043, 13598]]\n",
    "        \n",
    "# Perform sentiment analysis on the cleaned reviews\n",
    "sentiment_analysis(clean_reviews(reviews_data_sample))\n",
    "\n",
    "# Select two specific reviews to compare for similarity\n",
    "first_review = reviews_data[34]\n",
    "second_review = reviews_data[18754]\n",
    "\n",
    "# Define a function to calculate the similarity between two reviews\n",
    "def similarity_analysis(review_1, review_2):\n",
    "    # Calculate the similarity score between the two spaCy documents using 'en_core_web_md' for word vectors\n",
    "    similarity_score = nlpx(review_1).similarity(nlpx(review_2))\n",
    "    \n",
    "    # Return the calculated similarity score\n",
    "    return similarity_score\n",
    "\n",
    "# Perform similarity analysis on the selected reviews and print the results\n",
    "print(f\"\\nFirst Review: {first_review}\")\n",
    "print(f\"Second Review: {second_review}\")\n",
    "print(f\"Similarity: {similarity_analysis(first_review, second_review)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ecb06",
   "metadata": {},
   "source": [
    "Write a brief report or summary in a PDF file:\n",
    "\n",
    "sentiment_analysis_report.pdf that must include:\n",
    "\n",
    "5.1. A description of the dataset used.\n",
    "\n",
    "5.2. Details of the preprocessing steps.\n",
    "\n",
    "5.3. Evaluation of results.\n",
    "\n",
    "5.4. Insights into the model's strengths and limitations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcfba4",
   "metadata": {},
   "source": [
    "5.1. Dataset Description\n",
    "The dataset used in this analysis consists of a collection of Amazon product reviews for AmazonBasics AAA Performance Alkaline Batteries.\n",
    "The dataset has a shape of 24 columns and 28332 rows.\n",
    "It includes a variety of fields such as:\n",
    "Date Added: The date when the product was listed in the dataset. \n",
    "Name: The product name. \n",
    "Asins: Amazon Standard Identification Numbers. \n",
    "Image URLs: URLs to the product images. \n",
    "Manufacturer: Manufacturer of the product.\n",
    "And many more, but the target field is:\n",
    "Reviews: This includes several sub-fields such as the date of the review, whether the product was recommended, review ID, the number of helpful votes, rating, the review text itself, the review title, and the username of the reviewer.\n",
    "The sub-field that we will be utilising in this project is the textual content of the review itself under the column reviews.text.\n",
    "5.2. Preprocessing Steps\n",
    "The preprocessing of the dataset involved several key steps to prepare the text data for sentiment analysis:\n",
    "Loading and Cleaning: The dataset was loaded into a pandas DataFrame, and any rows with missing values in the reviews.text column were dropped to ensure the analysis only included complete reviews. .dropna() was used.\n",
    "Tokenisation and Cleaning: Using spaCy, each review was processed to tokenise the text, converting it into a series of tokens or words. During this process, stopwords and punctuation were removed. Additionally, all tokens were converted to lowercase to maintain consistency and avoid duplication based on case differences. .str(), .strip(), .lower(), .is_stop, .is_punct all utilised.\n",
    "SpacyTextBlob Integration: The spaCy pipeline was extended with SpacyTextBlob for sentiment analysis, enabling the extraction of sentiment polarity and subjectivity scores directly from the processed text.\n",
    "5.3. Evaluation of Results\n",
    "The sentiment analysis yielded polarity and subjectivity scores for each cleaned review. Polarity scores range from -1 (very negative) to 1 (very positive), providing a quantitative measure of sentiment. Subjectivity scores, on the other hand, range from 0 (objective) to 1 (subjective), indicating the degree of personal opinion or factual content in the review.\n",
    "By analysing these scores, it was possible to classify each review as Positive, Negative, or Neutral, providing a clear overview of customer sentiment towards products. The similarity analysis further allowed for the comparison of textual content between reviews, identifying how similar two reviews are in terms of their sentiment and content.\n",
    "In practice, the sample selected to test sentiment analysis saw a range of polarity from 0.7 to -0.5, and subjectivity of 1.0 to 0.0.\n",
    "The classification of reviews into 'Positive', 'Negative', and 'Neutral' categories based on polarity scores demonstrated an effective measure of sentiment. For instance, a review described as \"bulk expensive way products like\" garnered a polarity of -0.5 and a subjectivity of 0.7, accurately reflecting a 'Negative' sentiment. Conversely, a review noting \"battery battery good price\" with a polarity of 0.7 and subjectivity of 0.6 was aptly classified as 'Positive', indicating satisfaction.\n",
    "Moreover, the similarity analysis, particularly between the two random reviews with a high similarity score of 0.88, underscores the model's ability to detect semantic similarities in reviews that may vary in context but share underlying sentiment. This similarity score shows the model's sophistication in identifying and measuring the degree of sentiment alignment between reviews.\n",
    "In essence, the sentiment and similarity analysis conducted offers a comprehensive snapshot of consumer sentiment, reflecting a broad spectrum of opinions and experiences. The application of these analyses presents a compelling case for the integration of NLP technologies in evaluating based on consumer feedback.\n",
    "5.4. Insights into the Model's Strengths and Limitations\n",
    "The model has many areas which it is particularly strong in, and areas where it could be improved, the below lists these areas.\n",
    "Strengths:\n",
    "The use of spaCy and SpacyTextBlob provides a flexible and powerful toolset for NLP tasks for efficient text preprocessing and sentiment analysis.\n",
    "The preprocessing and analysis pipeline is capable of handling large datasets, thanks to spaCy's optimised design. The preprocessing steps are well-organised and is effective at removing noise-inducing elements like stopwords and punctuation, which can enhance the clarity of sentiment analysis.\n",
    "By focusing on the 'reviews.text' data, the analysis is kept directly relevant to the sentiment task at hand.\n",
    "The iterative approach to cleaning and analysis ensures efficient memory usage, particularly with large datasets.\n",
    "By combining sentiment polarity and subjectivity analysis, the model offers nuanced insights into customer opinions and the nature of their reviews. The integration of TextBlob facilitates straightforward sentiment extraction, providing reliable polarity and subjectivity scores.\n",
    "The function sentiment_analysis can be scaled and integrated into larger systems, highlighting the model's adaptability.\n",
    "The modular code structure allows for easy adaptations to new datasets or various text inputs.\n",
    "The sentiment analysis model used specifically for review similarity was purposefully changed to the medium model to allow the use of word vectors to direct the similarity score.\n",
    "Limitations:\n",
    "The model may not always fully capture the context or nuances of certain phrases and idioms, potentially leading to inaccuracies in sentiment classification. This is partly due to the use of the small language model and also a possibility of over cleaning text before sentiment analysis.\n",
    "The current implementation is tailored for English text data. Adapting the pipeline for other languages requires loading different spaCy language models and may necessitate adjustments in preprocessing steps.\n",
    "The model might struggle with highly subjective or sarcastic content, where the literal interpretation of text does not accurately reflect the intended sentiment. This is an issue seen in many sentiment analysis models.\n",
    "The preprocessing steps involve cleaning the dataset by removing stopwords, punctuation, and altering the case of the words to lower. While this streamlines the text for analysis, it may inadvertently remove key information that contributes to the sentiment. For instance, stopwords, though often considered \"noise,\" can sometimes carry sentiment; similarly, punctuation can denote intensity or sentiment that would be lost when removed. This is often referred to as over cleaning.\n",
    "Lemmatisation was deliberately avoided in this analysis as it could strip words of their suffixes which contain added sentiment, leading to a loss of sentimentality in the reviews. Initial trials indicated that lemmatisation could result in reviews that lost significant context and meaning, impacting the accuracy of sentiment analysis. This can be seen as a positive, but this is not seen across the board, in other cases it can improve the accuracy of the subjectivity score.\n",
    "The conversion of text to lowercase may eliminate useful information such as emphasis denoted by capitalisation, which can be particularly relevant in expressing sentiments.\n",
    "In conclusion, the sentiment analysis model provides valuable insights into customer sentiments expressed in Amazon product reviews. While it demonstrates strong capabilities in text preprocessing and sentiment evaluation, awareness of its limitations is crucial for interpreting the results accurately. \n",
    "Future work could explore more advanced models that incorporate contextual understanding and sarcasm detection to enhance accuracy further. It's important to strike a balance between cleaning the text to aid in analysis and preserving the linguistic features that convey sentiment, this can differ from different use cases, for example product reviews vs a script for a play. We can improve the model experimenting further with lemmatisation and training the model with previously assessed reviews. Also employ techniques to handle negations and intensifiers effectively. Words like \"not\" can change the sentiment of an otherwise positive or negative statement, while intensifiers like \"very\" can amplify a sentiment. The model often lacked in this specific area. Also, fine tune the model to be aware of the industry it is working in. This will help the model understand the context the text is in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d27ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f6a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
